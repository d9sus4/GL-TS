{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8456321490029355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Parameters\n",
    "n_samples = 1000\n",
    "n_rows = 100\n",
    "n_columns = 10\n",
    "missing_rate_label_1 = 0.2\n",
    "missing_rate_label_0 = 0.1\n",
    "other_columns_missing_rate = 0.1\n",
    "\n",
    "# Generate labels (0 or 1)\n",
    "labels = np.random.randint(2, size=n_samples)\n",
    "\n",
    "# Generate data with the specific missing pattern\n",
    "def generate_data(n_samples, n_rows, n_columns, labels):\n",
    "\n",
    "    data = np.random.normal(loc=0, scale=1, size=(n_samples, n_rows, n_columns))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Apply missing rate for the last column based on the label\n",
    "        if labels[i] == 1:\n",
    "            missing_mask = np.random.rand(n_rows) < missing_rate_label_1\n",
    "        else:\n",
    "            missing_mask = np.random.rand(n_rows) < missing_rate_label_0\n",
    "        data[i, :, -1][missing_mask] = np.nan\n",
    "\n",
    "        # Apply random missing rate for other columns\n",
    "        for j in range(n_columns - 1):\n",
    "            missing_mask = np.random.rand(n_rows) < other_columns_missing_rate\n",
    "            data[i, :, j][missing_mask] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "# Generate dataset\n",
    "data = generate_data(n_samples, n_rows, n_columns, labels)\n",
    "\n",
    "# Flatten each matrix into a vector (to use with XGBoost)\n",
    "data_flattened = data.reshape(n_samples, -1)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_flattened, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost model\n",
    "xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "# Fit the model\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "auroc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5729324830448427, 0.6042109525255592, 0.6042109525255592)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Zero Imputer\n",
    "zero_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "# Mean Imputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Linear Imputer (custom)\n",
    "class LinearImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.means = np.nanmean(X, axis=0)\n",
    "        self.single_values = [np.nan if np.sum(~np.isnan(X[:, i])) != 1 else X[~np.isnan(X[:, i]), i][0] for i in range(X.shape[1])]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_filled = X.copy()\n",
    "        for i in range(X.shape[1]):\n",
    "            if np.isnan(self.single_values[i]):\n",
    "                X_filled[:, i] = np.where(np.isnan(X[:, i]), self.means[i], X[:, i])\n",
    "            else:\n",
    "                X_filled[:, i] = np.where(np.isnan(X[:, i]), self.single_values[i], X[:, i])\n",
    "        return X_filled\n",
    "\n",
    "linear_imputer = LinearImputer()\n",
    "\n",
    "# Define a function to train and test using XGBoost, and return AUROC score\n",
    "def train_and_test(X_train, y_train, X_test, y_test):\n",
    "    xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "    y_pred_proba = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "    return roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Fit imputers to training data and transform both train and test sets\n",
    "X_train_zero = zero_imputer.fit_transform(X_train)\n",
    "X_test_zero = zero_imputer.transform(X_test)\n",
    "X_train_mean = mean_imputer.fit_transform(X_train)\n",
    "X_test_mean = mean_imputer.transform(X_test)\n",
    "X_train_linear = linear_imputer.fit_transform(X_train)\n",
    "X_test_linear = linear_imputer.transform(X_test)\n",
    "\n",
    "# Train and test using each imputer\n",
    "auroc_zero = train_and_test(X_train_zero, y_train, X_test_zero, y_test)\n",
    "auroc_mean = train_and_test(X_train_mean, y_train, X_test_mean, y_test)\n",
    "auroc_linear = train_and_test(X_train_linear, y_train, X_test_linear, y_test)\n",
    "\n",
    "auroc_zero, auroc_mean, auroc_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4907379289401761"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "n_samples = 1000\n",
    "n_rows = 100\n",
    "n_columns = 10\n",
    "missing_rate = 0.1\n",
    "\n",
    "# Generate data with the specific missing pattern\n",
    "def generate_data2(n_samples, n_rows, n_columns, labels):\n",
    "\n",
    "    # Oscillating missing rate function for class 1\n",
    "    def oscillating_missing_rate(t):\n",
    "        return missing_rate + 0.05 * np.sin(np.pi * t / (n_rows - 1))  # t is normalized to [0, 1]\n",
    "\n",
    "    data = np.random.normal(loc=0, scale=1, size=(n_samples, n_rows, n_columns))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Apply missing rate for the last column based on the label\n",
    "        if labels[i] == 1:\n",
    "            # Oscillating missing rate for the last column\n",
    "            for t in range(n_rows):\n",
    "                if np.random.rand() < oscillating_missing_rate(t):\n",
    "                    data[i, t, -1] = np.nan\n",
    "        else:\n",
    "            missing_mask = np.random.rand(n_rows) < missing_rate\n",
    "            data[i, :, -1][missing_mask] = np.nan\n",
    "\n",
    "        # Apply random missing rate for other columns\n",
    "        for j in range(n_columns - 1):\n",
    "            missing_mask = np.random.rand(n_rows) < missing_rate\n",
    "            data[i, :, j][missing_mask] = np.nan\n",
    "\n",
    "    return data\n",
    "\n",
    "# Generate dataset\n",
    "data = generate_data2(n_samples, n_rows, n_columns, labels)\n",
    "\n",
    "# Flatten each matrix into a vector (to use with XGBoost)\n",
    "data_flattened = data.reshape(n_samples, -1)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_flattened, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost model\n",
    "xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "# Fit the model\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUROC\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/d9sus4/miniconda3/envs/playground/lib/python3.11/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48061544690758173, 0.5390221682356514, 0.4790970746026925)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Zero Imputer\n",
    "zero_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "# Mean Imputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Linear Imputer (custom)\n",
    "class LinearImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.means = np.nanmean(X, axis=0)\n",
    "        self.single_values = [\n",
    "            np.nan if np.sum(~np.isnan(X[:, i])) != 1 else X[~np.isnan(X[:, i]), i][0]\n",
    "            for i in range(X.shape[1])\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_filled = X.copy()\n",
    "        for i in range(X.shape[1]):\n",
    "            non_missing_indices = np.where(~np.isnan(X[:, i]))[0]\n",
    "            missing_indices = np.where(np.isnan(X[:, i]))[0]\n",
    "            \n",
    "            # Case 1: At least two non-missing values -> Linear interpolation\n",
    "            if len(non_missing_indices) >= 2:\n",
    "                X_filled[:, i] = pd.Series(X[:, i]).interpolate(method='linear', limit_direction='both').to_numpy()\n",
    "\n",
    "            # Case 2: Exactly one non-missing value -> Impute with that single value\n",
    "            elif len(non_missing_indices) == 1:\n",
    "                X_filled[missing_indices, i] = self.single_values[i]\n",
    "\n",
    "            # Case 3: No non-missing values -> Impute with the column mean from training data\n",
    "            else:\n",
    "                X_filled[missing_indices, i] = self.means[i]\n",
    "\n",
    "        return X_filled\n",
    "\n",
    "linear_imputer = LinearImputer()\n",
    "\n",
    "# Define a function to train and test using XGBoost, and return AUROC score\n",
    "def train_and_test(X_train, y_train, X_test, y_test):\n",
    "    xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "    y_pred_proba = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "    return roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Fit imputers to training data and transform both train and test sets\n",
    "X_train_zero = zero_imputer.fit_transform(X_train)\n",
    "X_test_zero = zero_imputer.transform(X_test)\n",
    "X_train_mean = mean_imputer.fit_transform(X_train)\n",
    "X_test_mean = mean_imputer.transform(X_test)\n",
    "X_train_linear = linear_imputer.fit_transform(X_train)\n",
    "X_test_linear = linear_imputer.transform(X_test)\n",
    "\n",
    "# Train and test using each imputer\n",
    "auroc_zero = train_and_test(X_train_zero, y_train, X_test_zero, y_test)\n",
    "auroc_mean = train_and_test(X_train_mean, y_train, X_test_mean, y_test)\n",
    "auroc_linear = train_and_test(X_train_linear, y_train, X_test_linear, y_test)\n",
    "\n",
    "auroc_zero, auroc_mean, auroc_linear\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
